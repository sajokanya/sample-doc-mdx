---
title: "DirectQuery tutorial"
description: "Learn how to connect to external databases and query data directly without loading it into memory."
---

## What is DirectQuery?

DirectQuery is a feature in Atoti that allows you to connect to external databases and query data directly without loading it into Atoti's memory. This approach is beneficial for:

- Large datasets that exceed available memory
- Real-time data that changes frequently  
- Compliance requirements that prevent data duplication
- Scenarios where you need the most up-to-date information

## Prerequisites

Before starting this tutorial, ensure you have:

- Atoti Python SDK installed (`pip install atoti`)
- Access to a supported database (PostgreSQL, SQL Server, Oracle, etc.)
- Database connection credentials
- Basic knowledge of SQL and Python

## Basic DirectQuery setup

### Step 1: Import Atoti and create a session

```python
import atoti as tt

# Create a standard Atoti session
session = tt.create_session()
```

### Step 2: Connect to your database

Based on the Atoti documentation, you can connect to external databases using connection strings. The exact method depends on your database type:

```python
# Example connection pattern (verify exact syntax in Atoti docs)
# Note: This is illustrative - check official documentation for precise API

# For PostgreSQL
connection_string = "postgresql://username:password@host:port/database"

# For SQL Server  
connection_string = "mssql://username:password@host:port/database"

# For Oracle
connection_string = "oracle://username:password@host:port/service"
```

### Step 3: Create tables from external sources

```python
# Create a table that references external data
# Note: Verify exact method names in official Atoti documentation

# This is a conceptual example - actual API may differ
external_table = session.read_sql(
    "SELECT * FROM sales_data WHERE date >= '2023-01-01'",
    connection_string
)
```

## Working with external data

### Creating cubes from external tables

```python
# Create a cube from your external data
cube = session.create_cube(external_table)

# Access measures for aggregations
m = cube.measures

# Define basic measures using Atoti's aggregation functions
m["Total Sales"] = tt.agg.sum(external_table["amount"])
m["Transaction Count"] = tt.agg.count()
m["Average Sale"] = tt.agg.mean(external_table["amount"])
```

### Filtering and querying

```python
# Apply filters to your data
filtered_data = external_table[
    (external_table["region"] == "North America") &
    (external_table["amount"] > 1000)
]

# Create hierarchies for analysis
cube.hierarchies["Time"] = [external_table["date"]]
cube.hierarchies["Geography"] = [external_table["region"]]
```

## Performance considerations

### Database optimization

1. **Use selective queries**: Filter data at the database level
2. **Index appropriately**: Ensure your database tables are properly indexed
3. **Limit result sets**: Use LIMIT clauses for large datasets
4. **Monitor connections**: Be mindful of database connection limits

### Query best practices

```python
# Good: Filter at the source
efficient_query = """
SELECT product_id, region, amount, date 
FROM sales_data 
WHERE date >= '2023-01-01' 
  AND region IN ('US', 'Canada')
  AND amount > 0
"""

# Better than pulling all data and filtering in Atoti
```

## Error handling and troubleshooting

### Common connection issues

```python
try:
    # Test your database connection
    test_query = "SELECT 1"
    result = session.read_sql(test_query, connection_string)
    print("Database connection successful")
except Exception as e:
    print(f"Connection failed: {e}")
    # Check connection string, credentials, network access
```

### Performance troubleshooting

1. **Slow queries**: Review your SQL query performance in the database
2. **Memory issues**: Monitor both Atoti and database memory usage
3. **Network latency**: Consider database location and connection quality
4. **Connection timeouts**: Adjust timeout settings if needed

## Security considerations

### Connection security

- Use SSL/TLS connections when available
- Store credentials securely (environment variables, key vaults)
- Use read-only database accounts when possible
- Implement proper network security (VPNs, firewalls)

```python
# Example of using environment variables for credentials
import os

connection_string = f"postgresql://{os.getenv('DB_USER')}:{os.getenv('DB_PASS')}@{os.getenv('DB_HOST')}/{os.getenv('DB_NAME')}"
```

## Integration patterns

### Combining external and in-memory data

```python
# Load some data into memory
in_memory_table = session.read_csv("local_data.csv")

# Connect to external data
external_table = session.read_sql(
    "SELECT * FROM remote_data", 
    connection_string
)

# Join them for analysis (verify exact join syntax in docs)
combined_cube = session.create_cube(
    # Join logic here - check Atoti documentation for exact syntax
)
```

## Important notes

**‚ö†Ô∏è API Verification Required**: The code examples in this tutorial are illustrative and based on common patterns. Always verify the exact API methods and parameters in the official Atoti documentation, as:

- Method names may differ (`read_sql` vs other connection methods)
- Configuration parameters may have different names or structures  
- Connection string formats may vary by database type
- Some features may require specific Atoti versions or licenses

**üìö Official Documentation**: For the most accurate and up-to-date information, consult:
- [Atoti Python SDK Documentation](https://docs.activeviam.com/products/atoti/python-sdk/latest/)
- Database-specific connection guides
- Performance tuning recommendations

## Next steps

After mastering basic DirectQuery concepts:

1. **Explore advanced SQL**: Use complex queries with joins and aggregations
2. **Optimize performance**: Implement caching and connection pooling strategies  
3. **Scale your solution**: Consider distributed database architectures
4. **Monitor and maintain**: Set up logging and performance monitoring

Remember to always test your specific use case with your actual data and database configuration.