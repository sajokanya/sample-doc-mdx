---
title: "DirectQuery tutorial"
description: "Learn how to connect to external databases and query data directly without loading it into memory."
---

## What is DirectQuery?

DirectQuery is a feature in Atoti that allows you to connect to external databases and query data directly without loading it into Atoti's memory. This approach is beneficial for:

- Large datasets that exceed available memory
- Real-time data that changes frequently  
- Compliance requirements that prevent data duplication
- Scenarios where you need the most up-to-date information

## Prerequisites

Before starting this tutorial, ensure you have:

- Atoti Python SDK installed (`pip install atoti`)
- Access to a supported database (PostgreSQL, SQL Server, Oracle, etc.)
- Database connection credentials
- Basic knowledge of SQL and Python

## DirectQuery concepts

### How DirectQuery works

Instead of loading data into Atoti's memory, DirectQuery:

1. **Maintains connections** to your external databases
2. **Translates queries** from Atoti's interface into SQL
3. **Executes queries** directly against the source database
4. **Returns results** without storing the full dataset

### Supported databases

Atoti typically supports major database systems including:
- PostgreSQL
- Microsoft SQL Server
- Oracle Database
- MySQL
- Other JDBC-compatible databases

*Consult the official Atoti documentation for the complete list of supported databases and versions.*

## Setting up DirectQuery

### Step 1: Prepare your database

Ensure your database is:
- **Accessible** from your Atoti environment
- **Properly indexed** for the queries you'll run
- **Configured** with appropriate user permissions
- **Optimized** for the expected query patterns

### Step 2: Connection configuration

You'll need to configure database connections with:
- **Host and port** information
- **Database name** and schema details
- **Authentication credentials** (username/password or other methods)
- **Connection parameters** (timeouts, SSL settings, etc.)

### Step 3: Define your data sources

When setting up DirectQuery tables, consider:
- **Which tables** or views to expose
- **What columns** are needed for analysis
- **How to filter** data at the source
- **What joins** might be required

## Code implementation

**‚ö†Ô∏è Important**: The following sections describe the conceptual approach. For actual code examples, you must refer to the official Atoti documentation as API methods and syntax may vary.

### Basic connection pattern

```python
import atoti as tt

# Create session
session = tt.create_session()

# Connection setup (exact syntax varies - check Atoti docs)
# connection_config = {
#     "type": "database_type",
#     "host": "your_host",
#     "port": your_port,
#     "database": "your_database",
#     "username": "your_username",
#     "password": "your_password"
# }

# Create external table reference (verify method name in docs)
# external_table = session.connect_to_database(connection_config, "table_name")
```

### Working with external data

```python
# Conceptual workflow - verify exact API in documentation

# 1. Define your external data source
# external_data = session.[connection_method](...)

# 2. Create cube from external source  
# cube = session.[cube_creation_method](external_data)

# 3. Define measures and hierarchies
# measures = cube.measures
# measures["measure_name"] = [aggregation_function](external_data["column"])

# 4. Query your data
# result = cube.query(...)
```

## Performance optimization

### Database-level optimization

1. **Indexing strategy**
   - Create indexes on columns used in WHERE clauses
   - Index columns used for JOINs
   - Consider composite indexes for multi-column filters

2. **Query optimization**
   - Use selective WHERE clauses
   - Limit result sets with appropriate filters
   - Avoid SELECT * when possible

3. **Connection management**
   - Configure connection pooling
   - Set appropriate timeout values
   - Monitor connection usage

### Atoti-level optimization

1. **Data modeling**
   - Design efficient hierarchies
   - Use appropriate data types
   - Consider partitioning strategies

2. **Query patterns**
   - Cache frequently accessed results
   - Use incremental refresh when possible
   - Monitor query performance

## Security best practices

### Connection security

- **Use encrypted connections** (SSL/TLS) when available
- **Store credentials securely** using environment variables or key management systems
- **Use read-only accounts** for DirectQuery connections when possible
- **Implement network security** (VPNs, firewalls, IP restrictions)

### Access control

- **Limit database permissions** to only required tables and operations
- **Implement row-level security** in the database if needed
- **Monitor access patterns** and audit database connections
- **Use service accounts** rather than personal credentials

## Troubleshooting common issues

### Connection problems

1. **Network connectivity**
   - Verify host and port accessibility
   - Check firewall rules
   - Test basic network connectivity

2. **Authentication failures**
   - Verify credentials
   - Check account permissions
   - Ensure account is not locked

3. **Database-specific issues**
   - Check database server status
   - Verify database and schema names
   - Review database logs for errors

### Performance issues

1. **Slow queries**
   - Analyze query execution plans
   - Check for missing indexes
   - Review database statistics

2. **Connection timeouts**
   - Adjust timeout settings
   - Check network latency
   - Consider connection pooling

3. **Memory issues**
   - Monitor database server resources
   - Review query complexity
   - Consider result set size limits

## Integration patterns

### Hybrid architectures

You can combine DirectQuery with in-memory data:

- **Hot data** in memory for fast access
- **Cold data** via DirectQuery for completeness
- **Reference data** cached locally
- **Transactional data** queried directly

### Real-time scenarios

DirectQuery enables real-time analytics by:

- **Connecting to operational databases** for live data
- **Querying data warehouses** for historical context
- **Combining streaming data** with batch-processed data
- **Providing up-to-date dashboards** without data movement

## Next steps

To implement DirectQuery successfully:

1. **Review the official documentation** for exact API syntax and methods
2. **Test with small datasets** before scaling to production
3. **Monitor performance** and optimize as needed
4. **Implement proper security** measures from the start
5. **Plan for maintenance** and monitoring

## Important reminders

**üö® No Code Guarantees**: This tutorial provides conceptual guidance only. All code examples are illustrative and must be verified against the official Atoti documentation.

**üìñ Official Resources**: 
- [Atoti Python SDK Documentation](https://docs.activeviam.com/products/atoti/python-sdk/latest/)
- Database vendor documentation for connection specifics
- Atoti community forums and support channels

**‚úÖ Verification Required**: Before implementing:
- Check exact method names and parameters
- Verify supported database versions
- Test connection strings and authentication methods
- Validate performance with your specific use case